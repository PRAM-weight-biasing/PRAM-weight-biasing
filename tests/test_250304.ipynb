{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from network import InfModel\n",
    "\n",
    "folder_name = 'Test_2024-10-28_15-15_Resnet18_p0.3'\n",
    "model_name = 'local_pruned_model.pth'\n",
    "dir_name = os.getcwd() + '/TestRun/'\n",
    "folder_path = os.path.join(dir_name, folder_name)\n",
    "model_path = os.path.join(folder_path, model_name)\n",
    "\n",
    "# 모델 로드\n",
    "model = torch.load(model_path)\n",
    "inf_model = InfModel(model, \"cifar10\")\n",
    "analog_model = inf_model.ConvertModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensors : conv1.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer1.0.conv1.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer1.0.conv2.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer1.1.conv1.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer1.1.conv2.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer2.0.conv1.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer2.0.conv2.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer2.0.downsample.0.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer2.1.conv1.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer2.1.conv2.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer3.0.conv1.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer3.0.conv2.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer3.0.downsample.0.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer3.1.conv1.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer3.1.conv2.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer4.0.conv1.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer4.0.conv2.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer4.0.downsample.0.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer4.1.conv1.analog_module\n",
      "<class 'str'>\n",
      "Tensors : layer4.1.conv2.analog_module\n",
      "<class 'str'>\n",
      "Tensors : fc.analog_module\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for tensors in analog_model.get_weights():\n",
    "    print(\"Tensors :\", tensors)\n",
    "    print(type(tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv:  conv1.weight\n",
      "conv:  layer1.0.conv1.weight\n",
      "conv:  layer1.0.conv2.weight\n",
      "conv:  layer1.1.conv1.weight\n",
      "conv:  layer1.1.conv2.weight\n",
      "conv:  layer2.0.conv1.weight\n",
      "conv:  layer2.0.conv2.weight\n",
      "conv:  layer2.0.downsample.0.weight\n",
      "conv:  layer2.1.conv1.weight\n",
      "conv:  layer2.1.conv2.weight\n",
      "conv:  layer3.0.conv1.weight\n",
      "conv:  layer3.0.conv2.weight\n",
      "conv:  layer3.0.downsample.0.weight\n",
      "conv:  layer3.1.conv1.weight\n",
      "conv:  layer3.1.conv2.weight\n",
      "conv:  layer4.0.conv1.weight\n",
      "conv:  layer4.0.conv2.weight\n",
      "conv:  layer4.0.downsample.0.weight\n",
      "conv:  layer4.1.conv1.weight\n",
      "conv:  layer4.1.conv2.weight\n",
      "fc:  fc.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"weight\" in name and len(param.size()) > 1:  # Conv / FC layer만 처리\n",
    "        if \"fc\" in name or len(param.size()) == 2:  # Fully Connected Layer\n",
    "            print(\"fc: \", name)\n",
    "        elif \"conv\" in name or len(param.size()) == 4:  # Convolutional Layer\n",
    "            print(\"conv: \", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1.weight, Shape: torch.Size([64, 3, 3, 3]), Size: 4\n",
      "Layer: layer1.0.conv1.weight, Shape: torch.Size([64, 64, 3, 3]), Size: 4\n",
      "Layer: layer1.0.conv2.weight, Shape: torch.Size([64, 64, 3, 3]), Size: 4\n",
      "Layer: layer1.1.conv1.weight, Shape: torch.Size([64, 64, 3, 3]), Size: 4\n",
      "Layer: layer1.1.conv2.weight, Shape: torch.Size([64, 64, 3, 3]), Size: 4\n",
      "Layer: layer2.0.conv1.weight, Shape: torch.Size([128, 64, 3, 3]), Size: 4\n",
      "Layer: layer2.0.conv2.weight, Shape: torch.Size([128, 128, 3, 3]), Size: 4\n",
      "Layer: layer2.0.downsample.0.weight, Shape: torch.Size([128, 64, 1, 1]), Size: 4\n",
      "Layer: layer2.1.conv1.weight, Shape: torch.Size([128, 128, 3, 3]), Size: 4\n",
      "Layer: layer2.1.conv2.weight, Shape: torch.Size([128, 128, 3, 3]), Size: 4\n",
      "Layer: layer3.0.conv1.weight, Shape: torch.Size([256, 128, 3, 3]), Size: 4\n",
      "Layer: layer3.0.conv2.weight, Shape: torch.Size([256, 256, 3, 3]), Size: 4\n",
      "Layer: layer3.0.downsample.0.weight, Shape: torch.Size([256, 128, 1, 1]), Size: 4\n",
      "Layer: layer3.1.conv1.weight, Shape: torch.Size([256, 256, 3, 3]), Size: 4\n",
      "Layer: layer3.1.conv2.weight, Shape: torch.Size([256, 256, 3, 3]), Size: 4\n",
      "Layer: layer4.0.conv1.weight, Shape: torch.Size([512, 256, 3, 3]), Size: 4\n",
      "Layer: layer4.0.conv2.weight, Shape: torch.Size([512, 512, 3, 3]), Size: 4\n",
      "Layer: layer4.0.downsample.0.weight, Shape: torch.Size([512, 256, 1, 1]), Size: 4\n",
      "Layer: layer4.1.conv1.weight, Shape: torch.Size([512, 512, 3, 3]), Size: 4\n",
      "Layer: layer4.1.conv2.weight, Shape: torch.Size([512, 512, 3, 3]), Size: 4\n",
      "Layer: fc.weight, Shape: torch.Size([10, 512]), Size: 2\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"weight\" in name and len(param.size()) > 1:  # Conv / FC layer만 처리\n",
    "        print(f\"Layer: {name}, Shape: {param.shape}, Size: {len(param.size())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: layer1.0.conv1.weight, Weight Min: -0.06962092220783234, Max: 0.0570538230240345\n",
      "Conductance Gp Min: 0.0, Max: 20.48731231689453\n",
      "Conductance Gm Min: 0.0, Max: 25.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from network import InfModel\n",
    "\n",
    "inf_model = InfModel(model, \"cifar10\")\n",
    "rpu_config = inf_model.SetConfig()\n",
    "analog_model = inf_model.ConvertModel()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name == \"layer1.0.conv1.weight\":\n",
    "        weights = param.data.cpu()\n",
    "        print(f\"Layer: {name}, Weight Min: {weights.min().item()}, Max: {weights.max().item()}\")  \n",
    "\n",
    "        # Conductance 변환 수행\n",
    "        conductance_pair = rpu_config.noise_model.g_converter.convert_to_conductances(weights)\n",
    "        gp, gm = conductance_pair[0]  # conductance_pair는 (gp, gm), params 반환\n",
    "\n",
    "        # 변환 후 값 확인\n",
    "        print(f\"Conductance Gp Min: {gp.min().item()}, Max: {gp.max().item()}\")\n",
    "        print(f\"Conductance Gm Min: {gm.min().item()}, Max: {gm.max().item()}\")\n",
    "\n",
    "        # 0이 아닌 값들만 필터링\n",
    "        gp_nonzero = gp[gp > 0]\n",
    "        gm_nonzero = gm[gm > 0]\n",
    "\n",
    "        if gp_nonzero.numel() == 0:\n",
    "            print(\"Gp has only zeros!\")\n",
    "        if gm_nonzero.numel() == 0:\n",
    "            print(\"Gm has only zeros!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[2.2551, 1.8474, 0.0000],\n",
       "          [9.9944, 9.5956, 6.1060],\n",
       "          [0.0000, 0.5084, 0.0000]],\n",
       "\n",
       "         [[0.8205, 5.6218, 3.9252],\n",
       "          [1.3712, 5.6487, 5.8839],\n",
       "          [1.6442, 5.0126, 7.3368]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.5088, 0.6506],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [5.2024, 6.4622, 4.0856],\n",
       "          [4.0103, 5.8225, 3.2814]],\n",
       "\n",
       "         [[0.0000, 1.8767, 0.0000],\n",
       "          [1.5007, 4.4959, 2.0774],\n",
       "          [1.2205, 2.7139, 1.4258]],\n",
       "\n",
       "         [[1.2745, 2.2185, 1.7382],\n",
       "          [2.9788, 3.6689, 2.6589],\n",
       "          [0.0000, 1.3872, 0.6146]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [2.7199, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.5834, 0.0000, 2.0082],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.5773, 0.0000, 1.6464]],\n",
       "\n",
       "         [[3.3866, 2.3633, 0.0000],\n",
       "          [2.4094, 2.4870, 0.0000],\n",
       "          [3.1627, 2.5455, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 1.0134, 0.0000]],\n",
       "\n",
       "         [[0.0000, 1.0146, 0.0000],\n",
       "          [0.0000, 0.5022, 0.0000],\n",
       "          [0.0000, 0.5106, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 1.0054],\n",
       "          [0.0000, 1.0030, 2.8552],\n",
       "          [0.0000, 0.9255, 2.7207]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 3.9610],\n",
       "          [0.0000, 0.0000, 3.4941],\n",
       "          [0.0000, 0.0000, 0.5440]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 1.8270, 1.4137],\n",
       "          [0.0000, 3.2287, 2.4281]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [2.3392, 0.0000, 0.3991]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.0000, 2.3613],\n",
       "          [0.0000, 0.0000, 3.2076],\n",
       "          [0.8656, 1.6331, 3.2136]],\n",
       "\n",
       "         [[1.3521, 0.0000, 0.0000],\n",
       "          [1.0887, 0.0000, 1.3944],\n",
       "          [0.7412, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.8588, 1.9944, 3.1159],\n",
       "          [0.0000, 0.8115, 2.4245],\n",
       "          [0.0000, 0.0000, 0.0000]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[1.2793, 2.8534, 1.3968],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 2.7900, 1.8795],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [1.8289, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.5280, 0.0000],\n",
       "          [0.7124, 0.5164, 0.0000],\n",
       "          [3.3710, 2.5064, 0.9920]],\n",
       "\n",
       "         [[0.0000, 0.5158, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[2.3283, 2.1341, 1.1602],\n",
       "          [3.5108, 3.4530, 1.8093],\n",
       "          [3.8089, 2.7091, 0.5271]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000],\n",
       "          [1.8262, 1.2138, 1.1767],\n",
       "          [1.9301, 1.0685, 0.0000]],\n",
       "\n",
       "         [[2.2555, 0.0000, 0.0000],\n",
       "          [3.9241, 0.0000, 0.0000],\n",
       "          [2.5802, 0.0000, 0.0000]],\n",
       "\n",
       "         [[3.4235, 4.1018, 2.4502],\n",
       "          [0.0000, 0.0000, 0.4352],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[2.3622, 0.0000, 0.0000],\n",
       "          [1.8691, 0.0000, 2.1601],\n",
       "          [0.0000, 0.0000, 0.4364]],\n",
       "\n",
       "         [[1.0805, 0.0000, 0.0000],\n",
       "          [0.8399, 0.0000, 0.5286],\n",
       "          [0.0000, 0.0000, 1.5317]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.7124, 1.3024, 1.1837],\n",
       "          [1.7300, 1.6352, 1.2789]]],\n",
       "\n",
       "\n",
       "        [[[0.0000, 0.0000, 0.0000],\n",
       "          [1.5769, 5.0400, 2.0984],\n",
       "          [1.1326, 4.2208, 2.4411]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.6653],\n",
       "          [0.0000, 0.0000, 0.8528],\n",
       "          [0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.9753, 2.7413, 1.4936]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 2.4507, 1.9770],\n",
       "          [0.5757, 5.3503, 3.3477]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [1.3814, 1.4170, 0.8097],\n",
       "          [1.6387, 1.9491, 2.0768]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 1.7069, 1.2583],\n",
       "          [1.1024, 2.3400, 1.2600]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2551, 1.8474, 0.0000,  ..., 1.1024, 2.3400, 1.2600])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.4221,  ..., 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(gp.flatten(), bins=100, alpha=1, label=\"Gp\")\n",
    "plt.hist(gm.flatten(), bins=100, alpha=0.5, label=\"Gm\")\n",
    "plt.grid(True)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Conductance 변환 함수 (FC / Conv 분리)\n",
    "def convert_weights_to_conductance(model, rpu_config):\n",
    "    conductance_list_fc = []\n",
    "    conductance_list_conv = []\n",
    "\n",
    "    min_gp_fc, min_gm_fc = None, None\n",
    "    min_gp_conv, min_gm_conv = None, None\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name and len(param.size()) > 1:  # Conv / FC layer만 처리\n",
    "            weights = param.data.cpu()\n",
    "            \n",
    "            # Conductance 변환 수행\n",
    "            conductance_pair = rpu_config.noise_model.g_converter.convert_to_conductances(weights)\n",
    "            gp, gm = conductance_pair[0]  # conductance_pair는 (gp, gm), params 반환\n",
    "\n",
    "            if len(param.size()) == 4:  # Convolutional Layer\n",
    "                conductance_list_conv.append((gp.flatten(), gm.flatten()))\n",
    "                \n",
    "            elif len(param.size()) == 2:  # Fully Connected Layer\n",
    "                conductance_list_fc.append((gp.flatten(), gm.flatten()))\n",
    "\n",
    "    return conductance_list_fc, conductance_list_conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_fc, g_conv = convert_weights_to_conductance(analog_model, rpu_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([3.8355, 9.5919, 5.2561,  ..., 0.0000, 1.1982, 0.0000]),\n",
       "  tensor([0.0000, 0.0000, 0.0000,  ..., 1.2208, 0.0000, 0.0000])),\n",
       " (tensor([2.2551, 1.8474, 0.0000,  ..., 1.1024, 2.3400, 1.2600]),\n",
       "  tensor([0.0000, 0.0000, 0.4221,  ..., 0.0000, 0.0000, 0.0000])),\n",
       " (tensor([1.6702, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]),\n",
       "  tensor([0.0000, 0.0000, 0.0000,  ..., 4.6494, 0.0000, 0.0000])),\n",
       " (tensor([4.1522, 2.4102, 1.2959,  ..., 0.0000, 2.0292, 0.0000]),\n",
       "  tensor([0.0000, 0.0000, 0.0000,  ..., 2.0190, 0.0000, 0.0000])),\n",
       " (tensor([3.6468, 5.5546, 0.0000,  ..., 0.0000, 0.0000, 4.3425]),\n",
       "  tensor([0.0000, 0.0000, 0.0000,  ..., 4.1632, 3.5297, 0.0000])),\n",
       " (tensor([2.9174, 4.6611, 0.0000,  ..., 2.0716, 0.0000, 0.0000]),\n",
       "  tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.5907, 0.0000])),\n",
       " (tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.6562, 1.7294]),\n",
       "  tensor([6.5752, 0.0000, 1.4366,  ..., 1.8976, 0.0000, 0.0000])),\n",
       " (tensor([7.4831, 0.0000, 0.0000,  ..., 5.7906, 0.0000, 0.0000]),\n",
       "  tensor([0.0000, 4.3502, 0.0000,  ..., 0.0000, 8.0629, 0.0000])),\n",
       " (tensor([7.0644, 0.0000, 0.0000,  ..., 3.5448, 0.0000, 0.0000]),\n",
       "  tensor([0.0000, 2.1687, 6.1565,  ..., 0.0000, 0.0000, 3.0054])),\n",
       " (tensor([0.0000, 0.0000, 4.7960,  ..., 4.2636, 7.9866, 4.4363]),\n",
       "  tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       " (tensor([0.0000, 0.0000, 0.0000,  ..., 5.1798, 3.2222, 0.0000]),\n",
       "  tensor([1.5390, 2.7235, 2.1308,  ..., 0.0000, 0.0000, 1.1320])),\n",
       " (tensor([2.0346, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]),\n",
       "  tensor([0.0000, 0.0000, 1.0897,  ..., 1.9959, 4.1022, 1.3959])),\n",
       " (tensor([0.0000, 1.2406, 1.4159,  ..., 1.2446, 0.0000, 0.0000]),\n",
       "  tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.3436])),\n",
       " (tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  tensor([0.7512, 1.6883, 1.4300,  ..., 1.4171, 2.4326, 1.3225])),\n",
       " (tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  tensor([1.3247, 0.9373, 1.8337,  ..., 0.0000, 0.9241, 0.0000])),\n",
       " (tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  tensor([ 1.0756,  1.3102,  0.9148,  ...,  5.2514, 11.9616,  8.2084])),\n",
       " (tensor([0.0000, 0.0000, 0.0000,  ..., 2.2874, 4.7341, 2.5467]),\n",
       "  tensor([0.5752, 1.0859, 0.5917,  ..., 0.0000, 0.0000, 0.0000])),\n",
       " (tensor([0.0000, 1.6725, 0.0000,  ..., 2.4670, 0.0000, 0.0000]),\n",
       "  tensor([ 2.1233,  0.0000,  4.7982,  ...,  0.0000,  2.1820, 13.0024])),\n",
       " (tensor([0.2823, 0.5505, 0.2558,  ..., 0.0000, 0.0000, 0.0000]),\n",
       "  tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       " (tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  tensor([0.1829, 0.3483, 0.1784,  ..., 0.0000, 0.0000, 0.0000])),\n",
       " (tensor([ 0.0000,  0.0000,  0.0000,  ...,  7.3837,  0.0000, 14.2151]),\n",
       "  tensor([1.7531, 2.2565, 0.0000,  ..., 0.0000, 0.0000, 0.0000]))]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_fc_all = np.concatenate([gp for gp, _ in g_fc]) if g_fc else np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.8355405,  9.591926 ,  5.2560782, ...,  7.383723 ,  0.       ,\n",
       "       14.215082 ], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_fc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_conv_all = np.concatenate([gp for gp, _ in g_conv]) if g_conv else np.array([])\n",
    "gp_conv_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 23.057903289794922, Nonzero count: 599\n",
      "Layer: conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 611\n",
      "Layer: layer1.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 20.48731231689453, Nonzero count: 12142\n",
      "Layer: layer1.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 13663\n",
      "Layer: layer1.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 11993\n",
      "Layer: layer1.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 22.807621002197266, Nonzero count: 13812\n",
      "Layer: layer1.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 11854\n",
      "Layer: layer1.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 22.523347854614258, Nonzero count: 13951\n",
      "Layer: layer1.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 20.688251495361328, Nonzero count: 11481\n",
      "Layer: layer1.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 14324\n",
      "Layer: layer2.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 21984\n",
      "Layer: layer2.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 20.28583526611328, Nonzero count: 29626\n",
      "Layer: layer2.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 44608\n",
      "Layer: layer2.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 20.20964241027832, Nonzero count: 58611\n",
      "Layer: layer2.0.downsample.0.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 2388\n",
      "Layer: layer2.0.downsample.0.analog_module.shared_weights, Gm Min: 0.0, Max: 18.820005416870117, Nonzero count: 3346\n",
      "Layer: layer2.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 43146\n",
      "Layer: layer2.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 20.8509578704834, Nonzero count: 60073\n",
      "Layer: layer2.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 41685\n",
      "Layer: layer2.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 14.936034202575684, Nonzero count: 61534\n",
      "Layer: layer3.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 89825\n",
      "Layer: layer3.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 13.064798355102539, Nonzero count: 116613\n",
      "Layer: layer3.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 180028\n",
      "Layer: layer3.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 17.884780883789062, Nonzero count: 232849\n",
      "Layer: layer3.0.downsample.0.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 9607\n",
      "Layer: layer3.0.downsample.0.analog_module.shared_weights, Gm Min: 0.0, Max: 17.912458419799805, Nonzero count: 13331\n",
      "Layer: layer3.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 24.894264221191406, Nonzero count: 166876\n",
      "Layer: layer3.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 246001\n",
      "Layer: layer3.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 22.089969635009766, Nonzero count: 138300\n",
      "Layer: layer3.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 274577\n",
      "Layer: layer4.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 18.462831497192383, Nonzero count: 383370\n",
      "Layer: layer4.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 442384\n",
      "Layer: layer4.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 676257\n",
      "Layer: layer4.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 7.882823944091797, Nonzero count: 975250\n",
      "Layer: layer4.0.downsample.0.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 39957\n",
      "Layer: layer4.0.downsample.0.analog_module.shared_weights, Gm Min: 0.0, Max: 16.51500701904297, Nonzero count: 51793\n",
      "Layer: layer4.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 1334754\n",
      "Layer: layer4.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 7.865383625030518, Nonzero count: 316753\n",
      "Layer: layer4.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 573782\n",
      "Layer: layer4.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 5.8290605545043945, Nonzero count: 1077725\n",
      "Layer: fc.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 669\n",
      "Layer: fc.analog_module.shared_weights, Gm Min: 0.0, Max: 3.7683143615722656, Nonzero count: 2915\n",
      "Conv Conductance Count: 0\n"
     ]
    }
   ],
   "source": [
    "def convert_weights_to_conductance(analog_model, rpu_config):\n",
    "    conductance_list_fc = []\n",
    "    conductance_list_conv = []\n",
    "\n",
    "    for name, param in analog_model.named_parameters():  #  analog_model에서 weight 가져오기\n",
    "        if \"weight\" in name and len(param.size()) > 1:  # Conv / FC layer만 처리\n",
    "            weights = param.data.cpu()\n",
    "\n",
    "            # Conductance 변환 수행\n",
    "            conductance_pair = rpu_config.noise_model.g_converter.convert_to_conductances(weights)\n",
    "            gp, gm = conductance_pair[0]  # conductance_pair는 (gp, gm), params 반환\n",
    "\n",
    "            # 0이 아닌 값 확인\n",
    "            gp_nonzero = gp[gp > 0]\n",
    "            gm_nonzero = gm[gm > 0]\n",
    "\n",
    "            print(f\"Layer: {name}, Gp Min: {gp.min().item()}, Max: {gp.max().item()}, Nonzero count: {gp_nonzero.numel()}\")\n",
    "            print(f\"Layer: {name}, Gm Min: {gm.min().item()}, Max: {gm.max().item()}, Nonzero count: {gm_nonzero.numel()}\")\n",
    "\n",
    "            if len(param.size()) == 4:  # Convolutional Layer\n",
    "                if gp_nonzero.numel() > 0 or gm_nonzero.numel() > 0:  # ✅ 0이 아닌 값이 있는 경우만 저장\n",
    "                    conductance_list_conv.append((gp.flatten(), gm.flatten()))\n",
    "\n",
    "            elif len(param.size()) == 2:  # Fully Connected Layer\n",
    "                if gp_nonzero.numel() > 0 or gm_nonzero.numel() > 0:\n",
    "                    conductance_list_fc.append((gp.flatten(), gm.flatten()))\n",
    "\n",
    "    return conductance_list_fc, conductance_list_conv\n",
    "\n",
    "# 실행\n",
    "g_fc, g_conv = convert_weights_to_conductance(analog_model, rpu_config)\n",
    "print(f\"Conv Conductance Count: {len(g_conv)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1.analog_module.shared_weights, Shape: torch.Size([64, 27]), Weight Min: -1.0, Max: 0.9223161339759827\n",
      "Layer: conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 23.057903289794922, Nonzero count: 599\n",
      "Layer: conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 611\n",
      "Layer: layer1.0.conv1.analog_module.shared_weights, Shape: torch.Size([64, 576]), Weight Min: -1.0, Max: 0.819492518901825\n",
      "Layer: layer1.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 20.48731231689453, Nonzero count: 12142\n",
      "Layer: layer1.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 13663\n",
      "Layer: layer1.0.conv2.analog_module.shared_weights, Shape: torch.Size([64, 576]), Weight Min: -0.9123048782348633, Max: 1.0\n",
      "Layer: layer1.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 11993\n",
      "Layer: layer1.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 22.807621002197266, Nonzero count: 13812\n",
      "Layer: layer1.1.conv1.analog_module.shared_weights, Shape: torch.Size([64, 576]), Weight Min: -0.9009339213371277, Max: 1.0\n",
      "Layer: layer1.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 11854\n",
      "Layer: layer1.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 22.523347854614258, Nonzero count: 13951\n",
      "Layer: layer1.1.conv2.analog_module.shared_weights, Shape: torch.Size([64, 576]), Weight Min: -1.0, Max: 0.827530026435852\n",
      "Layer: layer1.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 20.688251495361328, Nonzero count: 11481\n",
      "Layer: layer1.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 14324\n",
      "Layer: layer2.0.conv1.analog_module.shared_weights, Shape: torch.Size([128, 576]), Weight Min: -0.8114334344863892, Max: 1.0\n",
      "Layer: layer2.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 21984\n",
      "Layer: layer2.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 20.28583526611328, Nonzero count: 29626\n",
      "Layer: layer2.0.conv2.analog_module.shared_weights, Shape: torch.Size([128, 1152]), Weight Min: -0.8083857297897339, Max: 1.0\n",
      "Layer: layer2.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 44608\n",
      "Layer: layer2.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 20.20964241027832, Nonzero count: 58611\n",
      "Layer: layer2.0.downsample.0.analog_module.shared_weights, Shape: torch.Size([128, 64]), Weight Min: -0.7528002262115479, Max: 1.0\n",
      "Layer: layer2.0.downsample.0.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 2388\n",
      "Layer: layer2.0.downsample.0.analog_module.shared_weights, Gm Min: 0.0, Max: 18.820005416870117, Nonzero count: 3346\n",
      "Layer: layer2.1.conv1.analog_module.shared_weights, Shape: torch.Size([128, 1152]), Weight Min: -0.8340383172035217, Max: 1.0\n",
      "Layer: layer2.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 43146\n",
      "Layer: layer2.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 20.8509578704834, Nonzero count: 60073\n",
      "Layer: layer2.1.conv2.analog_module.shared_weights, Shape: torch.Size([128, 1152]), Weight Min: -0.5974413752555847, Max: 1.0\n",
      "Layer: layer2.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 41685\n",
      "Layer: layer2.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 14.936034202575684, Nonzero count: 61534\n",
      "Layer: layer3.0.conv1.analog_module.shared_weights, Shape: torch.Size([256, 1152]), Weight Min: -0.5225919485092163, Max: 1.0\n",
      "Layer: layer3.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 89825\n",
      "Layer: layer3.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 13.064798355102539, Nonzero count: 116613\n",
      "Layer: layer3.0.conv2.analog_module.shared_weights, Shape: torch.Size([256, 2304]), Weight Min: -0.715391218662262, Max: 1.0\n",
      "Layer: layer3.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 180028\n",
      "Layer: layer3.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 17.884780883789062, Nonzero count: 232849\n",
      "Layer: layer3.0.downsample.0.analog_module.shared_weights, Shape: torch.Size([256, 128]), Weight Min: -0.7164983153343201, Max: 1.0\n",
      "Layer: layer3.0.downsample.0.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 9607\n",
      "Layer: layer3.0.downsample.0.analog_module.shared_weights, Gm Min: 0.0, Max: 17.912458419799805, Nonzero count: 13331\n",
      "Layer: layer3.1.conv1.analog_module.shared_weights, Shape: torch.Size([256, 2304]), Weight Min: -1.0, Max: 0.9957705736160278\n",
      "Layer: layer3.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 24.894264221191406, Nonzero count: 166876\n",
      "Layer: layer3.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 246001\n",
      "Layer: layer3.1.conv2.analog_module.shared_weights, Shape: torch.Size([256, 2304]), Weight Min: -1.0, Max: 0.883598804473877\n",
      "Layer: layer3.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 22.089969635009766, Nonzero count: 138300\n",
      "Layer: layer3.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 274577\n",
      "Layer: layer4.0.conv1.analog_module.shared_weights, Shape: torch.Size([512, 2304]), Weight Min: -1.0, Max: 0.7385132312774658\n",
      "Layer: layer4.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 18.462831497192383, Nonzero count: 383370\n",
      "Layer: layer4.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 442384\n",
      "Layer: layer4.0.conv2.analog_module.shared_weights, Shape: torch.Size([512, 4608]), Weight Min: -0.3153129518032074, Max: 1.0\n",
      "Layer: layer4.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 676257\n",
      "Layer: layer4.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 7.882823944091797, Nonzero count: 975250\n",
      "Layer: layer4.0.downsample.0.analog_module.shared_weights, Shape: torch.Size([512, 256]), Weight Min: -0.6606003046035767, Max: 1.0\n",
      "Layer: layer4.0.downsample.0.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 39957\n",
      "Layer: layer4.0.downsample.0.analog_module.shared_weights, Gm Min: 0.0, Max: 16.51500701904297, Nonzero count: 51793\n",
      "Layer: layer4.1.conv1.analog_module.shared_weights, Shape: torch.Size([512, 4608]), Weight Min: -0.3146153390407562, Max: 1.0\n",
      "Layer: layer4.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 1334754\n",
      "Layer: layer4.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 7.865383625030518, Nonzero count: 316753\n",
      "Layer: layer4.1.conv2.analog_module.shared_weights, Shape: torch.Size([512, 4608]), Weight Min: -0.23316241800785065, Max: 1.0\n",
      "Layer: layer4.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 573782\n",
      "Layer: layer4.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 5.8290605545043945, Nonzero count: 1077725\n",
      "Layer: fc.analog_module.shared_weights, Shape: torch.Size([10, 512]), Weight Min: -0.15073257684707642, Max: 1.0\n",
      "Layer: fc.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 669\n",
      "Layer: fc.analog_module.shared_weights, Gm Min: 0.0, Max: 3.7683143615722656, Nonzero count: 2915\n",
      "✅ Conv Conductance Count: 0\n",
      "✅ FC Conductance Count: 21\n"
     ]
    }
   ],
   "source": [
    "def convert_weights_to_conductance(analog_model, rpu_config):\n",
    "    conductance_list_fc = []\n",
    "    conductance_list_conv = []\n",
    "\n",
    "    for name, param in analog_model.named_parameters():  # ✅ 변환된 모델에서 weight 가져오기\n",
    "        if \"analog_module.shared_weights\" in name:  # ✅ analog_model의 shared_weights만 선택\n",
    "            weights = param.data.cpu()\n",
    "            print(f\"Layer: {name}, Shape: {weights.shape}, Weight Min: {weights.min().item()}, Max: {weights.max().item()}\")  \n",
    "\n",
    "            # Conductance 변환 수행\n",
    "            conductance_pair = rpu_config.noise_model.g_converter.convert_to_conductances(weights)\n",
    "            gp, gm = conductance_pair[0]  # conductance_pair는 (gp, gm), params 반환\n",
    "\n",
    "            # 0이 아닌 값 확인\n",
    "            gp_nonzero = gp[gp > 0]\n",
    "            gm_nonzero = gm[gm > 0]\n",
    "\n",
    "            print(f\"Layer: {name}, Gp Min: {gp.min().item()}, Max: {gp.max().item()}, Nonzero count: {gp_nonzero.numel()}\")\n",
    "            print(f\"Layer: {name}, Gm Min: {gm.min().item()}, Max: {gm.max().item()}, Nonzero count: {gm_nonzero.numel()}\")\n",
    "\n",
    "            # ✅ Conv / FC 분리 (shared_weights는 3D로 나올 가능성 있음)\n",
    "            if len(weights.shape) >= 3:  # ✅ shared_weights에 맞게 수정\n",
    "                conductance_list_conv.append((gp.flatten(), gm.flatten()))\n",
    "            elif len(weights.shape) == 2:  # Fully Connected Layer\n",
    "                conductance_list_fc.append((gp.flatten(), gm.flatten()))\n",
    "\n",
    "    print(f\"✅ Conv Conductance Count: {len(conductance_list_conv)}\")\n",
    "    print(f\"✅ FC Conductance Count: {len(conductance_list_fc)}\")\n",
    "\n",
    "    return conductance_list_fc, conductance_list_conv\n",
    "\n",
    "# 실행\n",
    "g_fc, g_conv = convert_weights_to_conductance(analog_model, rpu_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1.analog_module.shared_weights, Shape: torch.Size([64, 27]), Weight Min: -1.0, Max: 0.9223161339759827\n",
      "Layer: conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 23.057903289794922, Nonzero count: 599\n",
      "Layer: conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 611\n",
      "Layer: layer1.0.conv1.analog_module.shared_weights, Shape: torch.Size([64, 576]), Weight Min: -1.0, Max: 0.819492518901825\n",
      "Layer: layer1.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 20.48731231689453, Nonzero count: 12142\n",
      "Layer: layer1.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 13663\n",
      "Layer: layer1.0.conv2.analog_module.shared_weights, Shape: torch.Size([64, 576]), Weight Min: -0.9123048782348633, Max: 1.0\n",
      "Layer: layer1.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 11993\n",
      "Layer: layer1.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 22.807621002197266, Nonzero count: 13812\n",
      "Layer: layer1.1.conv1.analog_module.shared_weights, Shape: torch.Size([64, 576]), Weight Min: -0.9009339213371277, Max: 1.0\n",
      "Layer: layer1.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 11854\n",
      "Layer: layer1.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 22.523347854614258, Nonzero count: 13951\n",
      "Layer: layer1.1.conv2.analog_module.shared_weights, Shape: torch.Size([64, 576]), Weight Min: -1.0, Max: 0.827530026435852\n",
      "Layer: layer1.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 20.688251495361328, Nonzero count: 11481\n",
      "Layer: layer1.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 14324\n",
      "Layer: layer2.0.conv1.analog_module.shared_weights, Shape: torch.Size([128, 576]), Weight Min: -0.8114334344863892, Max: 1.0\n",
      "Layer: layer2.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 21984\n",
      "Layer: layer2.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 20.28583526611328, Nonzero count: 29626\n",
      "Layer: layer2.0.conv2.analog_module.shared_weights, Shape: torch.Size([128, 1152]), Weight Min: -0.8083857297897339, Max: 1.0\n",
      "Layer: layer2.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 44608\n",
      "Layer: layer2.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 20.20964241027832, Nonzero count: 58611\n",
      "Layer: layer2.0.downsample.0.analog_module.shared_weights, Shape: torch.Size([128, 64]), Weight Min: -0.7528002262115479, Max: 1.0\n",
      "Layer: layer2.0.downsample.0.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 2388\n",
      "Layer: layer2.0.downsample.0.analog_module.shared_weights, Gm Min: 0.0, Max: 18.820005416870117, Nonzero count: 3346\n",
      "Layer: layer2.1.conv1.analog_module.shared_weights, Shape: torch.Size([128, 1152]), Weight Min: -0.8340383172035217, Max: 1.0\n",
      "Layer: layer2.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 43146\n",
      "Layer: layer2.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 20.8509578704834, Nonzero count: 60073\n",
      "Layer: layer2.1.conv2.analog_module.shared_weights, Shape: torch.Size([128, 1152]), Weight Min: -0.5974413752555847, Max: 1.0\n",
      "Layer: layer2.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 41685\n",
      "Layer: layer2.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 14.936034202575684, Nonzero count: 61534\n",
      "Layer: layer3.0.conv1.analog_module.shared_weights, Shape: torch.Size([256, 1152]), Weight Min: -0.5225919485092163, Max: 1.0\n",
      "Layer: layer3.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 89825\n",
      "Layer: layer3.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 13.064798355102539, Nonzero count: 116613\n",
      "Layer: layer3.0.conv2.analog_module.shared_weights, Shape: torch.Size([256, 2304]), Weight Min: -0.715391218662262, Max: 1.0\n",
      "Layer: layer3.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 180028\n",
      "Layer: layer3.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 17.884780883789062, Nonzero count: 232849\n",
      "Layer: layer3.0.downsample.0.analog_module.shared_weights, Shape: torch.Size([256, 128]), Weight Min: -0.7164983153343201, Max: 1.0\n",
      "Layer: layer3.0.downsample.0.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 9607\n",
      "Layer: layer3.0.downsample.0.analog_module.shared_weights, Gm Min: 0.0, Max: 17.912458419799805, Nonzero count: 13331\n",
      "Layer: layer3.1.conv1.analog_module.shared_weights, Shape: torch.Size([256, 2304]), Weight Min: -1.0, Max: 0.9957705736160278\n",
      "Layer: layer3.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 24.894264221191406, Nonzero count: 166876\n",
      "Layer: layer3.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 246001\n",
      "Layer: layer3.1.conv2.analog_module.shared_weights, Shape: torch.Size([256, 2304]), Weight Min: -1.0, Max: 0.883598804473877\n",
      "Layer: layer3.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 22.089969635009766, Nonzero count: 138300\n",
      "Layer: layer3.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 274577\n",
      "Layer: layer4.0.conv1.analog_module.shared_weights, Shape: torch.Size([512, 2304]), Weight Min: -1.0, Max: 0.7385132312774658\n",
      "Layer: layer4.0.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 18.462831497192383, Nonzero count: 383370\n",
      "Layer: layer4.0.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 25.0, Nonzero count: 442384\n",
      "Layer: layer4.0.conv2.analog_module.shared_weights, Shape: torch.Size([512, 4608]), Weight Min: -0.3153129518032074, Max: 1.0\n",
      "Layer: layer4.0.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 676257\n",
      "Layer: layer4.0.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 7.882823944091797, Nonzero count: 975250\n",
      "Layer: layer4.0.downsample.0.analog_module.shared_weights, Shape: torch.Size([512, 256]), Weight Min: -0.6606003046035767, Max: 1.0\n",
      "Layer: layer4.0.downsample.0.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 39957\n",
      "Layer: layer4.0.downsample.0.analog_module.shared_weights, Gm Min: 0.0, Max: 16.51500701904297, Nonzero count: 51793\n",
      "Layer: layer4.1.conv1.analog_module.shared_weights, Shape: torch.Size([512, 4608]), Weight Min: -0.3146153390407562, Max: 1.0\n",
      "Layer: layer4.1.conv1.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 1334754\n",
      "Layer: layer4.1.conv1.analog_module.shared_weights, Gm Min: 0.0, Max: 7.865383625030518, Nonzero count: 316753\n",
      "Layer: layer4.1.conv2.analog_module.shared_weights, Shape: torch.Size([512, 4608]), Weight Min: -0.23316241800785065, Max: 1.0\n",
      "Layer: layer4.1.conv2.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 573782\n",
      "Layer: layer4.1.conv2.analog_module.shared_weights, Gm Min: 0.0, Max: 5.8290605545043945, Nonzero count: 1077725\n",
      "Layer: fc.analog_module.shared_weights, Shape: torch.Size([10, 512]), Weight Min: -0.15073257684707642, Max: 1.0\n",
      "Layer: fc.analog_module.shared_weights, Gp Min: 0.0, Max: 25.0, Nonzero count: 669\n",
      "Layer: fc.analog_module.shared_weights, Gm Min: 0.0, Max: 3.7683143615722656, Nonzero count: 2915\n",
      "✅ Conv Conductance Count: 20\n",
      "✅ FC Conductance Count: 1\n"
     ]
    }
   ],
   "source": [
    "def convert_weights_to_conductance(analog_model, rpu_config):\n",
    "    conductance_list_fc = []\n",
    "    conductance_list_conv = []\n",
    "\n",
    "    for name, param in analog_model.named_parameters():\n",
    "        if \"analog_module.shared_weights\" in name:  # ✅ 변환된 모델의 shared_weights만 선택\n",
    "            weights = param.data.cpu()\n",
    "            print(f\"Layer: {name}, Shape: {weights.shape}, Weight Min: {weights.min().item()}, Max: {weights.max().item()}\")\n",
    "\n",
    "            # Conductance 변환 수행\n",
    "            conductance_pair = rpu_config.noise_model.g_converter.convert_to_conductances(weights)\n",
    "            gp, gm = conductance_pair[0]\n",
    "\n",
    "            # 0이 아닌 값 확인\n",
    "            gp_nonzero = gp[gp > 0]\n",
    "            gm_nonzero = gm[gm > 0]\n",
    "\n",
    "            print(f\"Layer: {name}, Gp Min: {gp.min().item()}, Max: {gp.max().item()}, Nonzero count: {gp_nonzero.numel()}\")\n",
    "            print(f\"Layer: {name}, Gm Min: {gm.min().item()}, Max: {gm.max().item()}, Nonzero count: {gm_nonzero.numel()}\")\n",
    "\n",
    "            # ✅ Conv와 FC 구별하는 새로운 방법 추가\n",
    "            if \"fc\" in name or weights.shape[0] <= 10:  # FC 레이어\n",
    "                conductance_list_fc.append((gp.flatten(), gm.flatten()))\n",
    "            else:  # Conv 레이어 (shared_weights 형태 적용)\n",
    "                conductance_list_conv.append((gp.flatten(), gm.flatten()))\n",
    "\n",
    "    print(f\"✅ Conv Conductance Count: {len(conductance_list_conv)}\")\n",
    "    print(f\"✅ FC Conductance Count: {len(conductance_list_fc)}\")\n",
    "\n",
    "    return conductance_list_fc, conductance_list_conv\n",
    "\n",
    "# 실행\n",
    "g_fc, g_conv = convert_weights_to_conductance(analog_model, rpu_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
